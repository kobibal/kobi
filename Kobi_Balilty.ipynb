{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import mysql as mysql\n",
    "from mysql import connector\n",
    "from mysql.connector import Error\n",
    "import os as os\n",
    "os.chdir(\"/Users/balilty/Downloads/wix\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config (dict): connection dictionary containing user, password, host, database\n",
    "config = pd.read_csv(\"config.csv\").to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 1 \n",
    "def get_api_data():\n",
    "    \"\"\"get API data\n",
    "            Returns:\n",
    "                DataFrame: the results returned in pandas dataframe.\n",
    "    \"\"\"\n",
    "    res = requests.get(\"https://randomuser.me/api/?results=4500\").json()\n",
    "    df = pd.json_normalize(res.get('results'),sep=\"_\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(df,table_name:str):\n",
    "    \"\"\"generate a dynamic create table statement based on each column max length and max int width\n",
    "            Parameters:\n",
    "                df (DataFrame): dataframe to generate\n",
    "                table name (str): the table name to create in DB\n",
    "\n",
    "            Returns:\n",
    "                String: create table statement\n",
    "    \"\"\"\n",
    "    measurer = np.vectorize(len)\n",
    "    max_char_for_object = measurer(df.select_dtypes(include=[object]).values.astype(str)).max(axis=0)\n",
    "    max_int_width = measurer(df.select_dtypes(include=[int]).values.astype(str)).max(axis=0)\n",
    "\n",
    "    # genarte dynamic create table statement based on columns dtypes\n",
    "    create_stat = f\"CREATE TABLE IF NOT EXISTS {table_name} (\" + \\\n",
    "    \", \".join([x + ' VARCHAR ('+str(max_char_for_object[i])+')' for i,x in enumerate(df.select_dtypes(include=[object]))]) +\\\n",
    "    \",\" + \", \".join([x + ' INT ('+str(max_int_width[i])+')' for i,x in enumerate(df.select_dtypes(include=[int]))]) +\");\"\n",
    "\n",
    "    return create_stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_and_insert_data(df,table_name:str,config):\n",
    "    \"\"\"drop old table if exists, create new table and insert data to DB\n",
    "            Parameters:\n",
    "                df (DataFrame): dataframe to insert DB\n",
    "                table name (str): the name of the table to create\n",
    "                config (dict): connection dictionary containing user, password, host, database\n",
    "    \"\"\"\n",
    "    connection = mysql.connector.connect(**config)\n",
    "    cursor = connection.cursor(buffered=True)\n",
    "    \n",
    "    # drop and execute table if exists\n",
    "    drop_stat = f\"\"\"DROP TABLE IF EXISTS {table_name};\"\"\"\n",
    "    cursor.execute(drop_stat)\n",
    "    \n",
    "    # check if df not empty, create table and insert data\n",
    "    if df.shape[0]>0:\n",
    "        #dynamic create statement based on each column max length and max int width\n",
    "        create_stat = create_table(df,table_name)\n",
    "        # execute create table statement\n",
    "        cursor.execute(create_stat)\n",
    "\n",
    "        # prepare list of tuples for each value\n",
    "        data = [tuple(x) for x in df.values.tolist()]\n",
    "\n",
    "        # prepare dynamic value list  (%s, %s...)\n",
    "        values = \", \".join(['%s' for c in df.columns])\n",
    "        \n",
    "        #prepare dynamic columns names\n",
    "        columns_name = \", \".join(df.columns)\n",
    "\n",
    "        # generate dynamic insert statement based on columns_name and values\n",
    "        insert_stat = f\"INSERT INTO {table_name} (\" + \\\n",
    "                        columns_name + \")  VALUES (\" +\\\n",
    "                        values +\")\"\n",
    "        # execute\n",
    "        cursor.executemany(insert_stat, data)\n",
    "       \n",
    "    # if df is empty, create table with dtype length 1\n",
    "    else:\n",
    "        create_stat = f\"CREATE TABLE IF NOT EXISTS {table_name} (\" +\\\n",
    "        \", \".join([x + ' VARCHAR (1)' for x in df.select_dtypes(include=[object])])  +\\\n",
    "        \",\" + \", \".join([x + ' INT (1)' for x in df.select_dtypes(include=[int])]) +\");\"\n",
    "        \n",
    "        # execute\n",
    "        cursor.execute(create_stat)\n",
    "        \n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2\n",
    "def task_2(df,config):\n",
    "    \"\"\"split df to 2 datasets by gender and create new tables in DB\n",
    "            Parameters:\n",
    "                df (DataFrame): dataframe to split and insert DB\n",
    "                config (dict): connection dictionary containing user, password, host, database\n",
    "    \"\"\"\n",
    "    df_male = df.loc[df.gender=='male']\n",
    "    df_female = df.loc[df.gender=='female']\n",
    "\n",
    "    # save data to DB\n",
    "    create_table_and_insert_data(df_male,\"Kobi_Balilty_test_male\",config)\n",
    "    create_table_and_insert_data(df_female,\"Kobi_Balilty_test_female\",config)\n",
    "    \n",
    "# I can do it also with Kobi_Balilty_test_male.to_sql(\"Kobi_Balilty_test_male\", con=engine, index=False, if_exists='replace',method='multi',chunksize=1000)\n",
    "# but it's slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 3\n",
    "def task_3(df):\n",
    "    \"\"\"split df to 10 datasets by gender age group of 10 (10s,20s 30s...)\n",
    "            Parameters:\n",
    "                df (DataFrame): dataframe to split\n",
    "            Returns:\n",
    "                df_by_group_age (dict): dictionary of DataFrames, with key of gender age group and value of DataFrame with all values that belong to the group.\n",
    "                                        for exmple to see data that belong to group with 20s you need to: df_by_group_age[20]\n",
    "    \"\"\"\n",
    "    cut_bins = [x for x in range(0,101,10)]\n",
    "    cut_names = [str(x)+'s' for x in cut_bins[:-1]]\n",
    "    df['group_age'] = pd.cut(df['dob_age'], bins=cut_bins, labels=cut_names, right=False)\n",
    "    df_by_group_age = {i:y for i,(x, y) in enumerate(df.groupby('group_age'))}\n",
    "    \n",
    "    return df_by_group_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 4\n",
    "def task_4(df_by_group_age,config):\n",
    "    \"\"\"insert each gender age groups to tables in DB\n",
    "            Parameters:\n",
    "                df_by_group_age (dict): dictionary to split and insert each DataFrame to DB\n",
    "                config (dict): connection dictionary containing user, password, host, database\n",
    "    \"\"\"\n",
    "    for index, df in df_by_group_age.items():\n",
    "        #df['group_age'] = df['group_age'].astype(object)\n",
    "        df.drop('group_age',axis=1,inplace=True)\n",
    "        create_table_and_insert_data(df, f\"Kobi_Balilty_test_{index}\", config)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(query,config):\n",
    "    \"\"\"execute query and get the data from DB\n",
    "            Parameters:\n",
    "                sql_query (str): the sql query to be executed as string\n",
    "                config (dict): connection dictionary containing user, password, host, database\n",
    "\n",
    "            Returns:\n",
    "                DataFrame: the results returned in pandas dataframe. if no results empty df returned.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    connection = mysql.connector.connect(**config)\n",
    "    cursor = connection.cursor(buffered=True)\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    \n",
    "    if cursor.rowcount > 0:\n",
    "        df = pd.DataFrame(data=cursor.fetchall(), columns=cursor.column_names)\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 5\n",
    "def task_5():\n",
    "    \"\"\"get top 20 last registered males and females from DB\n",
    "            Returns:\n",
    "                DataFrame: the results returned in pandas dataframe \n",
    "    \"\"\"\n",
    "    query = \"\"\"select * from(\n",
    "        select *,\n",
    "        dense_rank() over (\n",
    "        order by `registered_date` desc\n",
    "        )  as rank_id\n",
    "        from interview.Kobi_Balilty_test_female) as t\n",
    "        where rank_id <= 20\n",
    "        union all \n",
    "        select * from(\n",
    "        select *,\n",
    "        dense_rank() over (\n",
    "        order by `registered_date` desc\n",
    "        )  as rank_id\n",
    "        from interview.Kobi_Balilty_test_male) as t\n",
    "        where rank_id <= 20\"\"\"\n",
    "    Kobi_Balilty_test_20 = get_data(query, config)\n",
    "    Kobi_Balilty_test_20.drop('rank_id',inplace=True,axis=1)\n",
    "    create_table_and_insert_data(Kobi_Balilty_test_20, \"Kobi_Balilty_test_20\", config)\n",
    "    \n",
    "    return Kobi_Balilty_test_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 6\n",
    "def task_6(Kobi_Balilty_test_20,config):\n",
    "    \"\"\"get data from table Kobi_Balilty_test_5 and merge it with Kobi_Balilty_test_20\n",
    "            Parameters:\n",
    "                Kobi_Balilty_test_20 (DataFrame): dataframe with top 20 last registered males and females\n",
    "                config (dict): connection dictionary containing user, password, host, database\n",
    "\n",
    "            Returns:\n",
    "                DataFrame: the results returned in pandas dataframe\n",
    "                json: the results returned in json file\n",
    "    \"\"\"\n",
    "    query = \"\"\"select * from interview.Kobi_Balilty_test_5\"\"\"\n",
    "    Kobi_Balilty_test_5 = get_data(query,config)\n",
    "    first_json = Kobi_Balilty_test_5.merge(Kobi_Balilty_test_20, how='outer').to_json(\"first.json\")\n",
    "    task_6 = Kobi_Balilty_test_5.merge(Kobi_Balilty_test_20, how='outer')\n",
    "    \n",
    "    return first_json, task_6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 7\n",
    "def task_7(Kobi_Balilty_test_20,config):\n",
    "    \"\"\"get data from table Kobi_Balilty_test_2 and concat it with Kobi_Balilty_test_20\n",
    "            Parameters:\n",
    "                Kobi_Balilty_test_20 (DataFrame): dataframe with top 20 last registered males and females\n",
    "                config (dict): connection dictionary containing user, password, host, database\n",
    "\n",
    "            Returns:\n",
    "                DataFrame: the results returned in pandas dataframe\n",
    "                json: the results returned in json file\n",
    "    \"\"\"\n",
    "    query = \"\"\"select * from interview.Kobi_Balilty_test_2\"\"\"\n",
    "    Kobi_Balilty_test_2 = get_data(query,config)\n",
    "    second_json = pd.concat([Kobi_Balilty_test_2, Kobi_Balilty_test_20],ignore_index=True).to_json(\"second.json\")\n",
    "    task_7 = pd.concat([Kobi_Balilty_test_2, Kobi_Balilty_test_20],ignore_index=True)\n",
    "    return second_json, task_7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    status = 1\n",
    "    try:\n",
    "        df = get_api_data()\n",
    "        task_2(df,config)\n",
    "        df_by_group_age = task_3(df)\n",
    "        task_4(df_by_group_age,config)\n",
    "        Kobi_Balilty_test_20 = task_5()\n",
    "        task_6(Kobi_Balilty_test_20,config)\n",
    "        task_7(Kobi_Balilty_test_20,config)\n",
    "    except Error as e:\n",
    "        print(\"MYSql failed {}\".format(e))\n",
    "        status = 0\n",
    "    except Exception as e:\n",
    "        print(\"error {}\".format(e))\n",
    "        print(\"Exception occurred: {} - {}\".format(e, traceback.format_exc()))\n",
    "        status = 0\n",
    "    finally:\n",
    "        if status == 1:\n",
    "            print(\"Program End\")\n",
    "        else:\n",
    "            print(\"Program End With error\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program End\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
